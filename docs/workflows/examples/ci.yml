# CI/CD Workflow for Customer Churn Predictor
# This workflow runs on every pull request and push to main

name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.12"
  NODE_VERSION: "18"
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Code quality and security checks
  code-quality:
    name: Code Quality & Security
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for SonarQube

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Code formatting (Black)
        run: black --check src/ tests/ scripts/

      - name: Import sorting (isort)
        run: isort --check-only src/ tests/ scripts/

      - name: Linting (Flake8)
        run: flake8 src/ tests/ scripts/

      - name: Type checking (MyPy)
        run: mypy src/

      - name: Security scan (Bandit)
        run: bandit -r src/ -f json -o bandit-report.json
        continue-on-error: true

      - name: Dependency security (Safety)
        run: safety check --json --output safety-report.json
        continue-on-error: true

      - name: Upload security reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  # Unit and integration tests
  test:
    name: Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Create test directories
        run: |
          mkdir -p data/raw data/processed models logs

      - name: Run unit tests
        run: pytest tests/ -m "unit" -v --cov=src --cov-report=xml

      - name: Run integration tests
        run: pytest tests/ -m "integration" -v
        env:
          API_KEY: test-api-key

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        if: matrix.python-version == '3.12'
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  # Docker build and test
  docker:
    name: Docker Build & Test
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          target: production
          load: true
          tags: churn-predictor:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Test Docker image
        run: |
          # Start container
          docker run -d --name test-container \
            -p 8000:8000 \
            -e API_KEY=test-api-key \
            churn-predictor:test

          # Wait for startup
          sleep 30

          # Health check
          curl -f http://localhost:8000/health

          # Test prediction endpoint
          curl -X POST http://localhost:8000/predict \
            -H "Authorization: Bearer test-api-key" \
            -H "Content-Type: application/json" \
            -d '{"customer_data": {"tenure": 12, "MonthlyCharges": 65.50, "TotalCharges": 786.00, "gender": "Female", "SeniorCitizen": 0}}'

          # Cleanup
          docker stop test-container
          docker rm test-container

      - name: Scan Docker image for vulnerabilities
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'churn-predictor:test'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # Performance and load testing
  performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install locust

      - name: Start application
        run: |
          python -m src.api &
          sleep 10
        env:
          API_KEY: test-api-key

      - name: Run performance tests
        run: |
          locust -f tests/performance/locustfile.py \
            --headless \
            --users 50 \
            --spawn-rate 5 \
            --run-time 60s \
            --host http://localhost:8000 \
            --html performance-report.html

      - name: Upload performance report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-report
          path: performance-report.html

  # ML model validation
  model-validation:
    name: ML Model Validation
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create test data
        run: |
          mkdir -p data/raw data/processed models
          python -c "
          import pandas as pd
          import numpy as np
          np.random.seed(42)
          data = pd.DataFrame({
              'tenure': np.random.randint(1, 73, 1000),
              'MonthlyCharges': np.random.uniform(18.25, 118.75, 1000),
              'TotalCharges': np.random.uniform(18.25, 8500.0, 1000),
              'gender': np.random.choice(['Male', 'Female'], 1000),
              'SeniorCitizen': np.random.choice([0, 1], 1000),
              'Churn': np.random.choice(['Yes', 'No'], 1000)
          })
          data.to_csv('data/raw/customer_data.csv', index=False)
          "

      - name: Run ML pipeline
        run: |
          python scripts/run_preprocessing.py
          python scripts/run_training.py
          python scripts/run_evaluation.py --detailed

      - name: Validate model performance
        run: |
          python -c "
          import json
          with open('metrics.json', 'r') as f:
              metrics = json.load(f)
          assert metrics['accuracy'] > 0.7, f'Model accuracy {metrics[\"accuracy\"]} below threshold'
          print(f'âœ“ Model validation passed: accuracy = {metrics[\"accuracy\"]}')
          "

  # Build summary
  build-summary:
    name: Build Summary
    runs-on: ubuntu-latest
    needs: [code-quality, test, docker, performance, model-validation]
    if: always()
    
    steps:
      - name: Check build status
        run: |
          echo "## Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Code Quality | ${{ needs.code-quality.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Tests | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Docker | ${{ needs.docker.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance | ${{ needs.performance.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Model Validation | ${{ needs.model-validation.result }} |" >> $GITHUB_STEP_SUMMARY

      - name: Fail if any job failed
        if: |
          needs.code-quality.result == 'failure' ||
          needs.test.result == 'failure' ||
          needs.docker.result == 'failure' ||
          needs.model-validation.result == 'failure'
        run: exit 1